{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸš‚ Railway Sleeper Detection & Classification\n",
                "**Train YOLOv8 Detection + ResNet Classification Models**\n",
                "\n",
                "This notebook trains:\n",
                "1. **YOLO Detector** - Finds sleepers in images (bounding boxes)\n",
                "2. **ResNet Classifier** - Classifies condition (Good/Fair/Poor)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“¦ Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install ultralytics -q\n",
                "!pip install albumentations -q"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import shutil\n",
                "from pathlib import Path\n",
                "import torch\n",
                "import numpy as np\n",
                "from PIL import Image\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "print(f\"PyTorch: {torch.__version__}\")\n",
                "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“‚ Dataset Setup\n",
                "The Kaggle dataset `wachyuutami/concrete-sleepers` has:\n",
                "- `data train/`: Good class (200), Fair Class (250), Poor class (250)\n",
                "- `data test/`: Good class (100), Fair Class (100), Poor class (100)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dataset path on Kaggle\n",
                "DATASET_PATH = \"/kaggle/input/concrete-sleepers/concrete railway sleepers\"\n",
                "\n",
                "# Verify dataset exists\n",
                "if os.path.exists(DATASET_PATH):\n",
                "    print(\"âœ… Dataset found!\")\n",
                "    for item in os.listdir(DATASET_PATH):\n",
                "        print(f\"  - {item}\")\n",
                "else:\n",
                "    print(\"âŒ Dataset not found. Make sure to add the dataset to your notebook.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ”§ Part 1: Prepare YOLO Detection Dataset\n",
                "Convert classification images to detection format with full-image bounding boxes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create YOLO dataset structure\n",
                "YOLO_DATASET = Path(\"/kaggle/working/sleeper_yolo_dataset\")\n",
                "\n",
                "for split in ['train', 'valid']:\n",
                "    (YOLO_DATASET / split / 'images').mkdir(parents=True, exist_ok=True)\n",
                "    (YOLO_DATASET / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "print(\"âœ… YOLO dataset directories created\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import random\n",
                "\n",
                "def convert_to_yolo_format(input_dir, output_dir, split='train', val_ratio=0.2):\n",
                "    \"\"\"\n",
                "    Convert classification dataset to YOLO detection format.\n",
                "    Since sleeper fills most of the frame, use full-image bounding box.\n",
                "    \"\"\"\n",
                "    all_images = []\n",
                "    \n",
                "    # Collect all images from all class folders\n",
                "    for class_folder in Path(input_dir).iterdir():\n",
                "        if not class_folder.is_dir():\n",
                "            continue\n",
                "        for img_file in class_folder.glob('*.jpg'):\n",
                "            all_images.append((img_file, class_folder.name))\n",
                "    \n",
                "    # Shuffle and split\n",
                "    random.seed(42)\n",
                "    random.shuffle(all_images)\n",
                "    \n",
                "    split_idx = int(len(all_images) * (1 - val_ratio))\n",
                "    train_images = all_images[:split_idx]\n",
                "    val_images = all_images[split_idx:]\n",
                "    \n",
                "    def process_split(images, split_name):\n",
                "        for img_path, class_name in images:\n",
                "            # Copy image\n",
                "            new_name = f\"{class_name.replace(' ', '_')}_{img_path.name}\"\n",
                "            dst_img = output_dir / split_name / 'images' / new_name\n",
                "            shutil.copy(img_path, dst_img)\n",
                "            \n",
                "            # Create YOLO label (class 0, full image bbox)\n",
                "            lbl_name = Path(new_name).stem + '.txt'\n",
                "            dst_lbl = output_dir / split_name / 'labels' / lbl_name\n",
                "            with open(dst_lbl, 'w') as f:\n",
                "                f.write('0 0.5 0.5 0.95 0.95\\n')\n",
                "        \n",
                "        return len(images)\n",
                "    \n",
                "    train_count = process_split(train_images, 'train')\n",
                "    val_count = process_split(val_images, 'valid')\n",
                "    \n",
                "    return train_count, val_count\n",
                "\n",
                "# Convert train data\n",
                "train_path = f\"{DATASET_PATH}/data train\"\n",
                "train_count, val_count = convert_to_yolo_format(train_path, YOLO_DATASET, val_ratio=0.15)\n",
                "\n",
                "print(f\"âœ… YOLO dataset created:\")\n",
                "print(f\"   Train: {train_count} images\")\n",
                "print(f\"   Valid: {val_count} images\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create data.yaml for YOLO training\n",
                "yaml_content = f\"\"\"# Sleeper Detection Dataset\n",
                "path: {YOLO_DATASET}\n",
                "train: train/images\n",
                "val: valid/images\n",
                "\n",
                "nc: 1\n",
                "names: ['sleeper']\n",
                "\"\"\"\n",
                "\n",
                "with open(YOLO_DATASET / 'data.yaml', 'w') as f:\n",
                "    f.write(yaml_content)\n",
                "\n",
                "print(\"âœ… data.yaml created\")\n",
                "print(yaml_content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸŽ¯ Part 2: Train YOLO Sleeper Detector"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from ultralytics import YOLO\n",
                "\n",
                "# Load YOLOv8 medium model (better accuracy)\n",
                "model = YOLO('yolov8m.pt')  # yolov8m for better accuracy on Kaggle GPU\n",
                "\n",
                "print(\"âœ… YOLOv8m model loaded\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train the model\n",
                "results = model.train(\n",
                "    data=str(YOLO_DATASET / 'data.yaml'),\n",
                "    epochs=100,\n",
                "    imgsz=640,\n",
                "    batch=16,\n",
                "    patience=20,\n",
                "    device=0,  # Use GPU\n",
                "    project='/kaggle/working/runs',\n",
                "    name='sleeper_detector',\n",
                "    exist_ok=True,\n",
                "    # Augmentation\n",
                "    augment=True,\n",
                "    mosaic=1.0,\n",
                "    mixup=0.1,\n",
                "    # Save best model\n",
                "    save=True,\n",
                "    plots=True\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display training results\n",
                "from IPython.display import Image as IPyImage, display\n",
                "\n",
                "results_dir = Path('/kaggle/working/runs/sleeper_detector')\n",
                "\n",
                "# Show confusion matrix\n",
                "if (results_dir / 'confusion_matrix.png').exists():\n",
                "    display(IPyImage(filename=str(results_dir / 'confusion_matrix.png')))\n",
                "\n",
                "# Show results\n",
                "if (results_dir / 'results.png').exists():\n",
                "    display(IPyImage(filename=str(results_dir / 'results.png')))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Validate and get metrics\n",
                "best_model = YOLO('/kaggle/working/runs/sleeper_detector/weights/best.pt')\n",
                "metrics = best_model.val()\n",
                "\n",
                "print(\"\\nðŸ“Š YOLO Sleeper Detection Results:\")\n",
                "print(f\"   mAP@50: {metrics.box.map50:.3f}\")\n",
                "print(f\"   mAP@50-95: {metrics.box.map:.3f}\")\n",
                "print(f\"   Precision: {metrics.box.p[0]:.3f}\")\n",
                "print(f\"   Recall: {metrics.box.r[0]:.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ§  Part 3: Train ResNet Sleeper Classifier\n",
                "Classify sleeper conditions: Good / Fair / Poor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader\n",
                "from torchvision import datasets, transforms, models\n",
                "from tqdm import tqdm\n",
                "\n",
                "# Device\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data transforms\n",
                "train_transforms = transforms.Compose([\n",
                "    transforms.Resize((224, 224)),\n",
                "    transforms.RandomHorizontalFlip(),\n",
                "    transforms.RandomRotation(15),\n",
                "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "val_transforms = transforms.Compose([\n",
                "    transforms.Resize((224, 224)),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "# Load datasets\n",
                "train_dataset = datasets.ImageFolder(f\"{DATASET_PATH}/data train\", transform=train_transforms)\n",
                "val_dataset = datasets.ImageFolder(f\"{DATASET_PATH}/data test\", transform=val_transforms)\n",
                "\n",
                "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
                "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
                "\n",
                "print(f\"Classes: {train_dataset.classes}\")\n",
                "print(f\"Train samples: {len(train_dataset)}\")\n",
                "print(f\"Val samples: {len(val_dataset)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load pretrained ResNet50\n",
                "model_resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
                "\n",
                "# Modify final layer for 3 classes (Good, Fair, Poor)\n",
                "num_classes = len(train_dataset.classes)\n",
                "model_resnet.fc = nn.Sequential(\n",
                "    nn.Dropout(0.5),\n",
                "    nn.Linear(model_resnet.fc.in_features, num_classes)\n",
                ")\n",
                "\n",
                "model_resnet = model_resnet.to(device)\n",
                "print(f\"âœ… ResNet50 loaded with {num_classes} output classes\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training setup\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.AdamW(model_resnet.parameters(), lr=0.0001, weight_decay=0.01)\n",
                "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n",
                "\n",
                "# Training loop\n",
                "NUM_EPOCHS = 30\n",
                "best_acc = 0\n",
                "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
                "\n",
                "for epoch in range(NUM_EPOCHS):\n",
                "    # Training\n",
                "    model_resnet.train()\n",
                "    train_loss = 0\n",
                "    train_correct = 0\n",
                "    \n",
                "    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS}'):\n",
                "        images, labels = images.to(device), labels.to(device)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        outputs = model_resnet(images)\n",
                "        loss = criterion(outputs, labels)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        train_loss += loss.item()\n",
                "        train_correct += (outputs.argmax(1) == labels).sum().item()\n",
                "    \n",
                "    train_loss /= len(train_loader)\n",
                "    train_acc = train_correct / len(train_dataset)\n",
                "    \n",
                "    # Validation\n",
                "    model_resnet.eval()\n",
                "    val_loss = 0\n",
                "    val_correct = 0\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for images, labels in val_loader:\n",
                "            images, labels = images.to(device), labels.to(device)\n",
                "            outputs = model_resnet(images)\n",
                "            loss = criterion(outputs, labels)\n",
                "            val_loss += loss.item()\n",
                "            val_correct += (outputs.argmax(1) == labels).sum().item()\n",
                "    \n",
                "    val_loss /= len(val_loader)\n",
                "    val_acc = val_correct / len(val_dataset)\n",
                "    \n",
                "    scheduler.step(val_loss)\n",
                "    \n",
                "    # Save history\n",
                "    history['train_loss'].append(train_loss)\n",
                "    history['val_loss'].append(val_loss)\n",
                "    history['train_acc'].append(train_acc)\n",
                "    history['val_acc'].append(val_acc)\n",
                "    \n",
                "    print(f'Epoch {epoch+1}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f}, Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}')\n",
                "    \n",
                "    # Save best model\n",
                "    if val_acc > best_acc:\n",
                "        best_acc = val_acc\n",
                "        torch.save(model_resnet.state_dict(), '/kaggle/working/sleeper_classifier_best.pt')\n",
                "        print(f'  âœ… Saved best model (acc={best_acc:.4f})')\n",
                "\n",
                "print(f\"\\nðŸŽ‰ Best Validation Accuracy: {best_acc:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot training history\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "ax1.plot(history['train_loss'], label='Train Loss')\n",
                "ax1.plot(history['val_loss'], label='Val Loss')\n",
                "ax1.set_xlabel('Epoch')\n",
                "ax1.set_ylabel('Loss')\n",
                "ax1.set_title('Training Loss')\n",
                "ax1.legend()\n",
                "\n",
                "ax2.plot(history['train_acc'], label='Train Acc')\n",
                "ax2.plot(history['val_acc'], label='Val Acc')\n",
                "ax2.set_xlabel('Epoch')\n",
                "ax2.set_ylabel('Accuracy')\n",
                "ax2.set_title('Training Accuracy')\n",
                "ax2.legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('/kaggle/working/training_history.png')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ’¾ Part 4: Save Models for Deployment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "\n",
                "# Create output directory\n",
                "output_dir = Path('/kaggle/working/models')\n",
                "output_dir.mkdir(exist_ok=True)\n",
                "\n",
                "# Copy YOLO model\n",
                "yolo_src = Path('/kaggle/working/runs/sleeper_detector/weights/best.pt')\n",
                "if yolo_src.exists():\n",
                "    shutil.copy(yolo_src, output_dir / 'sleeper_yolo_best.pt')\n",
                "    print(\"âœ… YOLO model saved\")\n",
                "\n",
                "# Copy ResNet model\n",
                "resnet_src = Path('/kaggle/working/sleeper_classifier_best.pt')\n",
                "if resnet_src.exists():\n",
                "    shutil.copy(resnet_src, output_dir / 'sleeper_resnet_best.pt')\n",
                "    print(\"âœ… ResNet classifier saved\")\n",
                "\n",
                "# Save model info\n",
                "model_info = {\n",
                "    'yolo': {\n",
                "        'model': 'yolov8m',\n",
                "        'classes': ['sleeper'],\n",
                "        'input_size': 640,\n",
                "        'file': 'sleeper_yolo_best.pt'\n",
                "    },\n",
                "    'resnet': {\n",
                "        'model': 'resnet50',\n",
                "        'classes': train_dataset.classes,\n",
                "        'input_size': 224,\n",
                "        'file': 'sleeper_resnet_best.pt',\n",
                "        'best_accuracy': best_acc\n",
                "    }\n",
                "}\n",
                "\n",
                "with open(output_dir / 'model_info.json', 'w') as f:\n",
                "    json.dump(model_info, f, indent=2)\n",
                "\n",
                "print(\"\\nðŸ“¦ Models saved to /kaggle/working/models/\")\n",
                "for f in output_dir.iterdir():\n",
                "    print(f\"  - {f.name} ({f.stat().st_size / 1024 / 1024:.1f} MB)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test detection on sample image\n",
                "from ultralytics import YOLO\n",
                "\n",
                "# Load trained model\n",
                "detector = YOLO('/kaggle/working/models/sleeper_yolo_best.pt')\n",
                "\n",
                "# Get a test image\n",
                "test_img_path = list(Path(f\"{DATASET_PATH}/data test/Good Class\").glob('*.jpg'))[0]\n",
                "\n",
                "# Run detection\n",
                "results = detector(test_img_path, conf=0.25)\n",
                "\n",
                "# Show result\n",
                "results[0].show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“¥ Download Models\n",
                "After training, download the models from `/kaggle/working/models/` and upload to your EC2 server."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"ðŸŽ‰ TRAINING COMPLETE!\")\n",
                "print(\"=\"*60)\n",
                "print(\"\\nModels saved to /kaggle/working/models/\")\n",
                "print(\"\\nTo use on EC2:\")\n",
                "print(\"1. Download sleeper_yolo_best.pt and sleeper_resnet_best.pt\")\n",
                "print(\"2. Upload to ~/Code_on_track/railway-yolo-detection/models/\")\n",
                "print(\"3. Restart the backend server\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}