# VGG Classification Training Guide

Complete guide for training VGG-based image classification models for railway component condition assessment.

## ðŸŽ¯ Overview

This approach uses **Transfer Learning with VGG** models (VGG16/VGG19) to classify railway components into different condition categories.

### YOLO vs VGG Comparison

| Aspect | YOLO (Object Detection) | VGG (Classification) |
|--------|------------------------|----------------------|
| **Goal** | Locate and classify defects | Classify overall component condition |
| **Output** | Bounding boxes + labels | Single class label per image |
| **Input** | Full images with multiple objects | Pre-cropped component images |
| **Labels** | Requires bbox coordinates | Requires folder-based organization |
| **Use Case** | Finding defects in images | Determining component health status |

## ðŸ“Š Dataset Preparation

### Step 1: Convert YOLO to Classification Format

Your Railway-2 YOLO dataset needs to be converted to classification format:

```bash
python convert_to_classification.py
```

This creates:
```
Railway-2-classification/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ Faulty/
â”‚   â”‚   â”œâ”€â”€ image_001.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ Normal/
â”‚       â”œâ”€â”€ image_101.jpg
â”‚       â””â”€â”€ ...
â””â”€â”€ validation/
    â”œâ”€â”€ Faulty/
    â””â”€â”€ Normal/
```

### Step 2: Manual Dataset Organization (Optional)

For multi-class classification (Rusted, Cracked, Broken, Normal):

```
railway_components/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ Normal/
â”‚   â”œâ”€â”€ Rusted/
â”‚   â”œâ”€â”€ Cracked/
â”‚   â”œâ”€â”€ Broken/
â”‚   â””â”€â”€ Damaged/
â””â”€â”€ validation/
    â”œâ”€â”€ Normal/
    â”œâ”€â”€ Rusted/
    â”œâ”€â”€ Cracked/
    â”œâ”€â”€ Broken/
    â””â”€â”€ Damaged/
```

**Recommended split:**
- Training: 70-80%
- Validation: 15-20%
- Test: 10-15%

## ðŸ§  Model Architecture

### VGG16 (Recommended for starting)
- **Layers:** 16 weight layers (13 conv + 3 FC)
- **Parameters:** ~138M (base) + custom head
- **Speed:** Fast
- **Accuracy:** Good

### VGG19 (For higher accuracy)
- **Layers:** 19 weight layers (16 conv + 3 FC)
- **Parameters:** ~144M (base) + custom head
- **Speed:** Slightly slower
- **Accuracy:** Better

### Custom Classification Head
```
VGG Base (frozen/fine-tuned)
    â†“
GlobalAveragePooling2D
    â†“
Dense(512, ReLU) + Dropout(0.5)
    â†“
Dense(256, ReLU) + Dropout(0.3)
    â†“
Dense(num_classes, Softmax)
```

## ðŸš€ Training Pipeline

### Two-Phase Training

#### Phase 1: Feature Extraction
- **Freeze** all VGG base layers
- Train only the custom classification head
- Learn to use pre-trained features
- Fast training (~10-20 epochs)

#### Phase 2: Fine-Tuning
- **Unfreeze** top 4 layers of VGG
- Train with lower learning rate
- Adapt features to railway components
- Better accuracy (~20-30 epochs)

### Training Script

```bash
python train_vgg_classification.py
```

### Configuration Options

Edit `train_vgg_classification.py`:

```python
# Model selection
MODEL_TYPE = 'VGG16'  # or 'VGG19'

# Training parameters
EPOCHS = 50
BATCH_SIZE = 32
LEARNING_RATE = 0.0001

# Fine-tuning
FREEZE_BASE = True
UNFREEZE_LAYERS = 4
```

## ðŸ“ˆ Expected Results

### Typical Performance (Railway Components)

| Metric | Phase 1 (Frozen) | Phase 2 (Fine-tuned) |
|--------|------------------|----------------------|
| Training Accuracy | 85-90% | 92-96% |
| Validation Accuracy | 80-85% | 88-94% |
| Training Time | 15-25 min | 20-35 min |

### Good Results Indicators
- âœ… Val accuracy > 85%
- âœ… Small gap between train/val accuracy
- âœ… Precision and recall > 0.80
- âœ… Low loss values (< 0.5)

### Warning Signs
- âš ï¸ Val accuracy < 70%
- âš ï¸ Large train/val gap (overfitting)
- âš ï¸ Loss not decreasing
- âš ï¸ Precision/recall imbalance

## ðŸ“Š Output Files

Training generates:

```
runs/vgg_classification/
â”œâ”€â”€ best_model_initial.keras          # Best model from Phase 1
â”œâ”€â”€ best_model_fine_tuned.keras       # Best model from Phase 2
â”œâ”€â”€ final_model.keras                 # Final trained model
â”œâ”€â”€ model.tflite                      # TensorFlow Lite (mobile)
â”œâ”€â”€ training_history_initial.png      # Phase 1 metrics plots
â”œâ”€â”€ training_history_fine_tuned.png   # Phase 2 metrics plots
â”œâ”€â”€ confusion_matrix.png              # Confusion matrix
â”œâ”€â”€ classification_report.txt         # Detailed metrics
â””â”€â”€ class_indices.json                # Class mapping
```

## ðŸ”® Inference / Prediction

### Single Image Prediction

```python
from predict_vgg import load_model_and_classes, predict_image

# Load model
model, class_names = load_model_and_classes()

# Predict
predicted_class, confidence, probs = predict_image(
    model, 
    class_names, 
    'path/to/railway_component.jpg'
)

print(f"Prediction: {predicted_class} ({confidence:.2%})")
```

### Batch Prediction

```python
from predict_vgg import batch_predict

results = batch_predict(
    model,
    class_names,
    'path/to/image/folder'
)

# Results is a list of dictionaries:
# [{'image': 'img1.jpg', 'predicted_class': 'Rusted', 'confidence': 0.92}, ...]
```

### Interactive Mode

```bash
python predict_vgg.py
```

Enter image paths to get instant predictions with visualization.

## ðŸŽ¨ Data Augmentation

Automatic augmentation applied during training:

- **Rotation:** Â±20 degrees
- **Width/Height shift:** 20%
- **Shear:** 20%
- **Zoom:** 20%
- **Horizontal flip:** Yes
- **Rescaling:** 0-1 normalization

This helps the model generalize to various conditions:
- Different angles
- Various lighting
- Different positions
- Mirrored components

## ðŸ”§ Troubleshooting

### Issue: Low Accuracy

**Solutions:**
1. Check data quality and labels
2. Increase epochs (50-100)
3. Use VGG19 instead of VGG16
4. Collect more training data
5. Adjust augmentation parameters

### Issue: Overfitting

**Symptoms:** Train accuracy >> Val accuracy

**Solutions:**
1. Increase dropout rates (0.5 â†’ 0.6)
2. Add more augmentation
3. Use smaller learning rate
4. Collect more validation data
5. Reduce model complexity

### Issue: Training Too Slow

**Solutions:**
1. Reduce batch size
2. Use VGG16 instead of VGG19
3. Reduce image size (224 â†’ 160)
4. Enable GPU acceleration
5. Use fewer epochs for Phase 1

### Issue: Class Imbalance

**Symptoms:** Poor performance on minority classes

**Solutions:**
1. Use class weights:
   ```python
   from sklearn.utils.class_weight import compute_class_weight
   
   class_weights = compute_class_weight(
       'balanced',
       classes=np.unique(train_labels),
       y=train_labels
   )
   ```
2. Oversample minority classes
3. Undersample majority classes
4. Use focal loss instead of categorical crossentropy

## ðŸ“± Deployment

### TensorFlow Lite (Mobile/Edge)

```python
import tensorflow as tf

# Convert model
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save
with open('model.tflite', 'wb') as f:
    f.write(tflite_model)
```

### TensorFlow.js (Web)

```bash
pip install tensorflowjs

tensorflowjs_converter \
    --input_format=keras \
    final_model.keras \
    web_model/
```

### ONNX (Universal)

```python
import tf2onnx

spec = (tf.TensorSpec((None, 224, 224, 3), tf.float32, name="input"),)
output_path = "model.onnx"

model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec)
with open(output_path, "wb") as f:
    f.write(model_proto.SerializeToString())
```

## ðŸŽ¯ Best Practices

### Data Collection
- âœ… Balanced classes (similar number of samples)
- âœ… High-quality images (clear, well-lit)
- âœ… Diverse conditions (angles, lighting, distances)
- âœ… Consistent image quality

### Training
- âœ… Start with frozen base (Phase 1)
- âœ… Monitor val_loss for early stopping
- âœ… Use learning rate scheduling
- âœ… Save checkpoints regularly

### Validation
- âœ… Keep validation set separate
- âœ… Test on unseen data
- âœ… Check confusion matrix
- âœ… Verify per-class performance

### Deployment
- âœ… Test on real-world images
- âœ… Measure inference time
- âœ… Consider model compression
- âœ… Monitor model performance

## ðŸ“š Further Improvements

### Advanced Techniques
1. **Ensemble Models:** Combine VGG16 + VGG19
2. **Attention Mechanisms:** Focus on important regions
3. **Multi-Task Learning:** Classify + localize simultaneously
4. **Self-Supervised Learning:** Use unlabeled data
5. **Test-Time Augmentation:** Average predictions over augmented versions

### Alternative Architectures
- **ResNet50/101:** Better for deeper networks
- **EfficientNet:** Better accuracy/speed tradeoff
- **MobileNet:** Faster inference for edge devices
- **Vision Transformer:** State-of-the-art accuracy

## ðŸ”— Resources

- [VGG Paper](https://arxiv.org/abs/1409.1556)
- [Transfer Learning Guide](https://www.tensorflow.org/tutorials/images/transfer_learning)
- [Keras Documentation](https://keras.io/api/applications/vgg/)
- [Image Classification Best Practices](https://www.tensorflow.org/tutorials/images/classification)

---

**Ready to train?**

```bash
# 1. Convert dataset
python convert_to_classification.py

# 2. Train model
python train_vgg_classification.py

# 3. Make predictions
python predict_vgg.py
```

Good luck! ðŸš‚âœ¨
